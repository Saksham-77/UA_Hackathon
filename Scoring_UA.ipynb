{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "238344c4-5977-482e-96dd-119e64ecfc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all data sources...\n",
      "Loaded Flight Level Data.csv successfully!\n",
      "Loaded PNR Flight Level Data.csv successfully!\n",
      "Loaded PNR Remark Level Data.csv successfully!\n",
      "Loaded Bag Level Data.csv successfully!\n",
      "Flight Data Columns: ['company_id', 'flight_number', 'scheduled_departure_date_local', 'scheduled_departure_station_code', 'scheduled_arrival_station_code', 'scheduled_departure_datetime_local', 'scheduled_arrival_datetime_local', 'actual_departure_datetime_local', 'actual_arrival_datetime_local', 'total_seats', 'fleet_type', 'carrier', 'scheduled_ground_time_minutes', 'actual_ground_time_minutes', 'minimum_turn_minutes']\n",
      "PNR Flight Data Columns: ['company_id', 'flight_number', 'scheduled_departure_date_local', 'scheduled_departure_station_code', 'scheduled_arrival_station_code', 'record_locator', 'pnr_creation_date', 'total_pax', 'is_child', 'basic_economy_ind', 'is_stroller_user', 'lap_child_count']\n",
      "PNR Remarks Data Columns: ['record_locator', 'pnr_creation_date', 'flight_number', 'special_service_request']\n",
      "Bag Data Columns: ['company_id', 'flight_number', 'scheduled_departure_date_local', 'scheduled_departure_station_code', 'scheduled_arrival_station_code', 'bag_tag_unique_number', 'bag_tag_issue_date', 'bag_type']\n",
      "Cleaning flight data...\n",
      "Preparing data for merging...\n",
      "Created flight_key in flight_data. Sample keys: ['2025-08-04_4792_ORD', '2025-08-03_920_ORD', '2025-08-10_1776_ORD', '2025-08-06_5790_ORD', '2025-08-05_1398_ORD']\n",
      "Created flight_key in pnr_flight_data. Sample keys: ['2025-08-04_2494_ORD', '2025-08-06_2483_ORD', '2025-08-01_1620_ORD', '2025-08-01_1620_ORD', '2025-08-01_1620_ORD']\n",
      "Created flight_key in bag_data. Sample keys: ['2025-08-01_1068_ORD', '2025-08-01_622_ORD', '2025-08-01_3718_ORD', '2025-08-01_294_ORD', '2025-08-01_2627_ORD']\n",
      "Removed duplicates. Flight data rows: 8063\n",
      "Engineering all required features...\n",
      "Merging pax_counts...\n",
      "Merging ssr_counts...\n",
      "Merging bag_analysis...\n",
      "Master feature table created.\n",
      "Calculating daily difficulty scores...\n",
      "Scoring complete.\n",
      "Generating EDA visualizations...\n",
      "\n",
      "1. Analyzing flight delays...\n",
      "Average Delay: 21.22 minutes\n",
      "Percentage of Flights Delayed: 49.72%\n",
      "\n",
      "2. Analyzing turnaround buffer...\n",
      "Number of flights with turnaround buffer <= 5 minutes: 765\n",
      "Percentage of flights with tight turns: 9.49%\n",
      "\n",
      "3. Analyzing transfer bag ratio...\n",
      "Average Transfer Bag Ratio: 0.5158\n",
      "\n",
      "4. Analyzing passenger loads and operational difficulty...\n",
      "Correlation between Load Factor and Difficulty Score: 0.30 (p-value: 0.0000)\n",
      "\n",
      "5. Analyzing SSR and delay relationship controlling for load...\n",
      "Warning: SSR vs. delay analysis skipped due to missing delay_minutes or flight_key.\n",
      "\n",
      "EDA visualizations saved as PNG files.\n",
      "\n",
      "Success! Flight Difficulty Score file created: 'final_output_ffbcf5f4-539a-49f1-93fc-b7c506cf6981.csv'\n",
      "\n",
      "Preview of final_output (first 5 rows):\n",
      "    scheduled_departure_date_local  flight_number scheduled_departure_station_code scheduled_arrival_station_code fleet_type  turnaround_buffer  load_factor  ssr_count  total_bags  transfer_bag_ratio  departure_hour  difficulty_score  daily_rank difficulty_class\n",
      "453                     2025-08-01           1811                              ORD                            MSP   B737-800                -37     1.210843       37.0         175            0.668571              12          0.588770         1.0        Difficult\n",
      "288                     2025-08-01           1584                              ORD                            LAX   A321-2NX                -62     1.295000        4.0         133            0.308271              10          0.554784         2.0        Difficult\n",
      "139                     2025-08-01           1502                              ORD                            RDU   B737-900                -56     1.083799        2.0         113            0.433628              14          0.523442         3.0        Difficult\n",
      "141                     2025-08-01           1363                              ORD                            LAX   A321-2NX                -50     1.205000       16.0         128            0.218750              12          0.515266         4.0        Difficult\n",
      "476                     2025-08-01            972                              ORD                            BRU    B787-10                591     1.122642       22.0         461            0.598698              17          0.498495         5.0        Difficult\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Set seaborn style for better visuals\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# --- 1. Load All Datasets with Error Handling ---\n",
    "print(\"Loading all data sources...\")\n",
    "required_files = [\n",
    "    'Flight Level Data.csv',\n",
    "    'PNR Flight Level Data.csv',\n",
    "    'PNR Remark Level Data.csv',\n",
    "    'Bag Level Data.csv'\n",
    "]\n",
    "dataframes = {}\n",
    "for file in required_files:\n",
    "    try:\n",
    "        dataframes[file] = pd.read_csv(file)\n",
    "        print(f\"Loaded {file} successfully!\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Please ensure '{file}' is in the same directory.\")\n",
    "        exit()\n",
    "    except pd.errors.ParserError as e:\n",
    "        print(f\"Error parsing {file}: {e}. Check file format.\")\n",
    "        exit()\n",
    "\n",
    "flight_data = dataframes['Flight Level Data.csv']\n",
    "pnr_flight_data = dataframes['PNR Flight Level Data.csv']\n",
    "pnr_remarks_data = dataframes['PNR Remark Level Data.csv']\n",
    "bag_data = dataframes['Bag Level Data.csv']\n",
    "\n",
    "# Print columns for debugging\n",
    "print(\"Flight Data Columns:\", flight_data.columns.tolist())\n",
    "print(\"PNR Flight Data Columns:\", pnr_flight_data.columns.tolist())\n",
    "print(\"PNR Remarks Data Columns:\", pnr_remarks_data.columns.tolist())\n",
    "print(\"Bag Data Columns:\", bag_data.columns.tolist())\n",
    "\n",
    "# --- 2. Clean Flight Data ---\n",
    "print(\"Cleaning flight data...\")\n",
    "def clean_flight_data(df):\n",
    "    datetime_cols = [\n",
    "        'scheduled_departure_datetime_local',\n",
    "        'scheduled_arrival_datetime_local',\n",
    "        'actual_departure_datetime_local',\n",
    "        'actual_arrival_datetime_local'\n",
    "    ]\n",
    "    for col in datetime_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce', utc=True)\n",
    "    \n",
    "    for col in ['scheduled_ground_time_minutes', 'actual_ground_time_minutes']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: max(0, x) if pd.notnull(x) else x)\n",
    "    \n",
    "    numeric_cols = ['total_seats', 'scheduled_ground_time_minutes', 'actual_ground_time_minutes', 'minimum_turn_minutes']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    critical_cols = ['flight_number', 'scheduled_departure_datetime_local', 'scheduled_arrival_datetime_local']\n",
    "    df = df.dropna(subset=[col for col in critical_cols if col in df.columns])\n",
    "    df = df[df['scheduled_arrival_datetime_local'] >= df['scheduled_departure_datetime_local']]\n",
    "    \n",
    "    return df\n",
    "\n",
    "flight_data = clean_flight_data(flight_data)\n",
    "\n",
    "# --- 3. Create a Consistent Flight Identifier ---\n",
    "print(\"Preparing data for merging...\")\n",
    "def create_flight_key(df, df_name=\"DataFrame\"):\n",
    "    date_col = 'scheduled_departure_date_local'\n",
    "    required_cols = [date_col, 'flight_number', 'scheduled_departure_station_code']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing columns {missing_cols} in {df_name}. Skipping flight_key creation for this DataFrame.\")\n",
    "        return None, df  # Return None for flight_key\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce').dt.date\n",
    "    invalid_rows = df[date_col].isnull().sum()\n",
    "    if invalid_rows > 0:\n",
    "        print(f\"Warning: Dropping {invalid_rows} rows with invalid {date_col} in {df_name}.\")\n",
    "        df = df.dropna(subset=[date_col])\n",
    "    if df['flight_number'].isnull().any() or df['scheduled_departure_station_code'].isnull().any():\n",
    "        print(f\"Warning: Null values in flight_number or scheduled_departure_station_code in {df_name}.\")\n",
    "        df = df.dropna(subset=['flight_number', 'scheduled_departure_station_code'])\n",
    "    flight_key = (df[date_col].astype(str) + '_' +\n",
    "                  df['flight_number'].astype(str) + '_' +\n",
    "                  df['scheduled_departure_station_code'].astype(str))\n",
    "    return flight_key, df\n",
    "\n",
    "# Create flight_key and update DataFrames\n",
    "flight_key_dict = {}\n",
    "for df, name in [(flight_data, 'flight_data'), (pnr_flight_data, 'pnr_flight_data'), (bag_data, 'bag_data')]:\n",
    "    flight_key, df_updated = create_flight_key(df, name)\n",
    "    flight_key_dict[name] = flight_key\n",
    "    if flight_key is not None:\n",
    "        df['flight_key'] = flight_key\n",
    "        print(f\"Created flight_key in {name}. Sample keys:\", df['flight_key'].head().tolist())\n",
    "    else:\n",
    "        print(f\"Skipped flight_key creation in {name} due to missing columns.\")\n",
    "    if df_updated.shape[0] < df.shape[0]:\n",
    "        print(f\"Updated {name} with {df_updated.shape[0]} rows after dropping invalid data.\")\n",
    "        if name == 'flight_data':\n",
    "            flight_data = df_updated\n",
    "        elif name == 'pnr_flight_data':\n",
    "            pnr_flight_data = df_updated\n",
    "        elif name == 'bag_data':\n",
    "            bag_data = df_updated\n",
    "\n",
    "# Remove duplicates from flight_data based on flight_key if created\n",
    "if 'flight_key' in flight_data.columns:\n",
    "    flight_data = flight_data.drop_duplicates(subset=['flight_key'], keep='first')\n",
    "    print(f\"Removed duplicates. Flight data rows: {len(flight_data)}\")\n",
    "else:\n",
    "    print(\"Warning: Skipping duplicate removal for flight_data due to missing flight_key.\")\n",
    "\n",
    "# --- 4. Engineer All Features from Source Data ---\n",
    "print(\"Engineering all required features...\")\n",
    "final_df = flight_data.copy()\n",
    "\n",
    "# 4.1: Turnaround Buffer and Departure Hour\n",
    "final_df['turnaround_buffer'] = final_df['scheduled_ground_time_minutes'] - final_df['minimum_turn_minutes']\n",
    "final_df['departure_hour'] = pd.to_datetime(final_df['scheduled_departure_datetime_local']).dt.hour\n",
    "\n",
    "# 4.2: Passenger Load Factor\n",
    "if 'total_pax' in pnr_flight_data.columns and 'total_seats' in final_df.columns and 'flight_key' in pnr_flight_data.columns and 'flight_key' in final_df.columns:\n",
    "    print(\"Merging pax_counts...\")\n",
    "    pax_counts = pnr_flight_data.groupby('flight_key')['total_pax'].sum().reset_index()\n",
    "    final_df = pd.merge(final_df, pax_counts, on='flight_key', how='left')\n",
    "    final_df['load_factor'] = final_df['total_pax'].div(final_df['total_seats'].replace(0, np.nan)).fillna(0)\n",
    "else:\n",
    "    print(\"Warning: Skipping passenger load factor merge due to missing columns or flight_key. Setting load_factor to 0.\")\n",
    "    final_df['load_factor'] = 0\n",
    "\n",
    "# 4.3: SSR Count\n",
    "if 'record_locator' in pnr_flight_data.columns and 'record_locator' in pnr_remarks_data.columns and 'flight_key' in pnr_flight_data.columns and 'flight_key' in final_df.columns:\n",
    "    print(\"Merging ssr_counts...\")\n",
    "    pnr_to_flight_map = pnr_flight_data[['record_locator', 'flight_key']].drop_duplicates()\n",
    "    remarks_with_key = pd.merge(pnr_remarks_data, pnr_to_flight_map, on='record_locator', how='left')\n",
    "    ssr_counts = remarks_with_key.groupby('flight_key').size().reset_index(name='ssr_count')\n",
    "    final_df = pd.merge(final_df, ssr_counts, on='flight_key', how='left')\n",
    "else:\n",
    "    print(\"Warning: Skipping SSR count merge due to missing columns or flight_key. Setting ssr_count to 0.\")\n",
    "    final_df['ssr_count'] = 0\n",
    "\n",
    "# 4.4: Baggage Metrics\n",
    "if 'bag_type' in bag_data.columns and 'flight_key' in bag_data.columns and 'flight_key' in final_df.columns:\n",
    "    print(\"Merging bag_analysis...\")\n",
    "    total_bags = bag_data.groupby('flight_key').size().reset_index(name='total_bags')\n",
    "    transfer_bags = bag_data[bag_data['bag_type'] == 'Transfer'].groupby('flight_key').size().reset_index(name='transfer_bags')\n",
    "    bag_analysis = pd.merge(total_bags, transfer_bags, on='flight_key', how='left')\n",
    "    bag_analysis['transfer_bag_ratio'] = (bag_analysis['transfer_bags'] / bag_analysis['total_bags']).fillna(0)\n",
    "    final_df = pd.merge(final_df, bag_analysis, on='flight_key', how='left')\n",
    "else:\n",
    "    print(\"Warning: Skipping baggage metrics merge due to missing columns or flight_key. Setting baggage metrics to 0.\")\n",
    "    final_df['total_bags'] = 0\n",
    "    final_df['transfer_bags'] = 0\n",
    "    final_df['transfer_bag_ratio'] = 0\n",
    "\n",
    "# Clean up by filling missing values from merges with 0\n",
    "final_df.fillna(0, inplace=True)\n",
    "print(\"Master feature table created.\")\n",
    "\n",
    "# --- 5. Daily Scoring Logic ---\n",
    "print(\"Calculating daily difficulty scores...\")\n",
    "WEIGHTS = {\n",
    "    'schedule_pressure': 0.35,\n",
    "    'baggage_complexity': 0.25,\n",
    "    'passenger_load': 0.15,\n",
    "    'service_demand': 0.15,\n",
    "    'system_strain': 0.10\n",
    "}\n",
    "\n",
    "def calculate_daily_scores(daily_flights):\n",
    "    df = daily_flights.copy()\n",
    "    df['schedule_pressure'] = (-df['turnaround_buffer']).clip(lower=0)\n",
    "    df['baggage_complexity'] = df['transfer_bag_ratio'] * df['total_bags']\n",
    "    df['passenger_load'] = df['load_factor']\n",
    "    df['service_demand'] = df['ssr_count']\n",
    "    df['system_strain'] = df['departure_hour']\n",
    "    features_to_normalize = ['schedule_pressure', 'baggage_complexity', 'passenger_load', 'service_demand', 'system_strain']\n",
    "    for feature in features_to_normalize:\n",
    "        min_val, max_val = df[feature].min(), df[feature].max()\n",
    "        if (max_val - min_val) > 0:\n",
    "            df[f'norm_{feature}'] = (df[feature] - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            df[f'norm_{feature}'] = 0\n",
    "    df['difficulty_score'] = sum(WEIGHTS[f] * df[f'norm_{f}'] for f in features_to_normalize)\n",
    "    df['daily_rank'] = df['difficulty_score'].rank(method='first', ascending=False)\n",
    "    rank_percentiles = df['daily_rank'] / len(df)\n",
    "    df['difficulty_class'] = np.select(\n",
    "        [rank_percentiles <= 0.20, rank_percentiles <= 0.80],\n",
    "        ['Difficult', 'Medium'], default='Easy'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "all_days_scored = final_df.groupby('scheduled_departure_date_local').apply(calculate_daily_scores).reset_index(drop=True)\n",
    "print(\"Scoring complete.\")\n",
    "\n",
    "output_columns = [\n",
    "    'scheduled_departure_date_local', 'flight_number', 'scheduled_departure_station_code',\n",
    "    'scheduled_arrival_station_code', 'fleet_type', 'turnaround_buffer',\n",
    "    'load_factor', 'ssr_count', 'total_bags', 'transfer_bag_ratio',\n",
    "    'departure_hour', 'difficulty_score', 'daily_rank', 'difficulty_class'\n",
    "]\n",
    "final_output = all_days_scored[output_columns].sort_values(by=['scheduled_departure_date_local', 'daily_rank'])\n",
    "\n",
    "# --- 6. EDA Visualizations ---\n",
    "print(\"Generating EDA visualizations...\")\n",
    "\n",
    "# 1. Average Delay and Percentage of Delayed Flights\n",
    "print(\"\\n1. Analyzing flight delays...\")\n",
    "if 'actual_departure_datetime_local' in flight_data.columns and 'scheduled_departure_datetime_local' in flight_data.columns:\n",
    "    flight_data['delay_minutes'] = (flight_data['actual_departure_datetime_local'] - \n",
    "                                   flight_data['scheduled_departure_datetime_local']).dt.total_seconds() / 60\n",
    "    avg_delay = flight_data['delay_minutes'].mean()\n",
    "    delayed_flights = flight_data[flight_data['delay_minutes'] > 0]\n",
    "    percent_delayed = (len(delayed_flights) / len(flight_data)) * 100 if len(flight_data) > 0 else 0\n",
    "\n",
    "    print(f\"Average Delay: {avg_delay:.2f} minutes\")\n",
    "    print(f\"Percentage of Flights Delayed: {percent_delayed:.2f}%\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(flight_data['delay_minutes'].dropna(), bins=50, kde=True)\n",
    "    plt.axvline(avg_delay, color='red', linestyle='--', label=f'Average Delay: {avg_delay:.2f} min')\n",
    "    plt.title('Distribution of Flight Delays')\n",
    "    plt.xlabel('Delay (Minutes)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'delay_distribution_{uuid.uuid4()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=flight_data['delay_minutes'].dropna())\n",
    "    plt.title('Boxplot of Flight Delays (Outliers Visible)')\n",
    "    plt.xlabel('Delay (Minutes)')\n",
    "    plt.savefig(f'delay_boxplot_{uuid.uuid4()}.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Warning: Delay calculation skipped due to missing datetime columns.\")\n",
    "\n",
    "# 2. Flights with Scheduled Ground Time Close to or Below Minimum Turn Minutes\n",
    "print(\"\\n2. Analyzing turnaround buffer...\")\n",
    "threshold = 5\n",
    "tight_turns = final_output[final_output['turnaround_buffer'] <= threshold]\n",
    "num_tight_turns = len(tight_turns)\n",
    "percent_tight_turns = (num_tight_turns / len(final_output)) * 100 if len(final_output) > 0 else 0\n",
    "\n",
    "print(f\"Number of flights with turnaround buffer <= {threshold} minutes: {num_tight_turns}\")\n",
    "print(f\"Percentage of flights with tight turns: {percent_tight_turns:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(final_output['turnaround_buffer'].dropna(), bins=50, kde=True)\n",
    "plt.axvline(threshold, color='red', linestyle='--', label=f'Threshold: {threshold} min')\n",
    "plt.title('Distribution of Turnaround Buffer')\n",
    "plt.xlabel('Turnaround Buffer (Minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.savefig(f'turnaround_buffer_distribution_{uuid.uuid4()}.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=final_output['turnaround_buffer'].dropna())\n",
    "plt.axvline(threshold, color='red', linestyle='--', label=f'Threshold: {threshold} min')\n",
    "plt.title('Boxplot of Turnaround Buffer (Outliers Visible)')\n",
    "plt.xlabel('Turnaround Buffer (Minutes)')\n",
    "plt.legend()\n",
    "plt.savefig(f'turnaround_buffer_boxplot_{uuid.uuid4()}.png')\n",
    "plt.close()\n",
    "\n",
    "# 3. Average Ratio of Transfer Bags vs. Total Bags\n",
    "print(\"\\n3. Analyzing transfer bag ratio...\")\n",
    "avg_transfer_ratio = final_output['transfer_bag_ratio'].mean()\n",
    "print(f\"Average Transfer Bag Ratio: {avg_transfer_ratio:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(final_output['transfer_bag_ratio'].dropna(), bins=50, kde=True)\n",
    "plt.axvline(avg_transfer_ratio, color='red', linestyle='--', label=f'Average: {avg_transfer_ratio:.4f}')\n",
    "plt.title('Distribution of Transfer Bag Ratio')\n",
    "plt.xlabel('Transfer Bag Ratio')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.savefig(f'transfer_bag_ratio_distribution_{uuid.uuid4()}.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=final_output['transfer_bag_ratio'].dropna())\n",
    "plt.title('Boxplot of Transfer Bag Ratio (Outliers Visible)')\n",
    "plt.xlabel('Transfer Bag Ratio')\n",
    "plt.savefig(f'transfer_bag_ratio_boxplot_{uuid.uuid4()}.png')\n",
    "plt.close()\n",
    "\n",
    "# 4. Passenger Loads and Correlation with Operational Difficulty\n",
    "print(\"\\n4. Analyzing passenger loads and operational difficulty...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(final_output['load_factor'].dropna(), bins=50, kde=True)\n",
    "plt.title('Distribution of Passenger Load Factor')\n",
    "plt.xlabel('Load Factor')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig(f'load_factor_distribution_{uuid.uuid4()}.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='load_factor', y='difficulty_score', data=final_output)\n",
    "sns.regplot(x='load_factor', y='difficulty_score', data=final_output, scatter=False, color='red')\n",
    "correlation, p_value = pearsonr(final_output['load_factor'].dropna(), final_output['difficulty_score'].dropna())\n",
    "plt.title(f'Load Factor vs. Difficulty Score (Correlation: {correlation:.2f}, p-value: {p_value:.4f})')\n",
    "plt.xlabel('Load Factor')\n",
    "plt.ylabel('Difficulty Score')\n",
    "plt.savefig(f'load_factor_vs_difficulty_{uuid.uuid4()}.png')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Correlation between Load Factor and Difficulty Score: {correlation:.2f} (p-value: {p_value:.4f})\")\n",
    "\n",
    "# 5. SSR and Delay Controlling for Load\n",
    "print(\"\\n5. Analyzing SSR and delay relationship controlling for load...\")\n",
    "if 'delay_minutes' in flight_data.columns and 'flight_key' in flight_data.columns and 'flight_key' in final_output.columns:\n",
    "    print(\"Merging delay_minutes for SSR analysis...\")\n",
    "    merged_df = pd.merge(final_output, flight_data[['flight_key', 'delay_minutes']], on='flight_key', how='left')\n",
    "    merged_df['load_factor_quartile'] = pd.qcut(merged_df['load_factor'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.scatterplot(x='ssr_count', y='delay_minutes', hue='load_factor_quartile', size='load_factor', data=merged_df)\n",
    "    plt.title('SSR Count vs. Delay Minutes by Load Factor Quartile')\n",
    "    plt.xlabel('SSR Count')\n",
    "    plt.ylabel('Delay Minutes')\n",
    "    plt.savefig(f'ssr_vs_delay_by_load_{uuid.uuid4()}.png')\n",
    "    plt.close()\n",
    "\n",
    "    for quartile in merged_df['load_factor_quartile'].unique():\n",
    "        subset = merged_df[merged_df['load_factor_quartile'] == quartile]\n",
    "        if len(subset) > 1:\n",
    "            corr, p_val = pearsonr(subset['ssr_count'].dropna(), subset['delay_minutes'].dropna())\n",
    "            print(f\"Correlation between SSR Count and Delay in {quartile} Load Factor: {corr:.2f} (p-value: {p_val:.4f})\")\n",
    "else:\n",
    "    print(\"Warning: SSR vs. delay analysis skipped due to missing delay_minutes or flight_key.\")\n",
    "\n",
    "print(\"\\nEDA visualizations saved as PNG files.\")\n",
    "output_filename = f'final_output_{uuid.uuid4()}.csv'\n",
    "final_output.to_csv(output_filename, index=False)\n",
    "print(f\"\\nSuccess! Flight Difficulty Score file created: '{output_filename}'\")\n",
    "print(\"\\nPreview of final_output (first 5 rows):\")\n",
    "print(final_output.head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97394f85-b739-4ac6-b8be-343bfc35ff1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
